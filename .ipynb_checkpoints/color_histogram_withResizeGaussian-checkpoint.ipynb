{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  color_histogram with no resize 1/2 image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T09:05:56.597567Z",
     "start_time": "2017-12-20T09:05:55.897309Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T09:05:33.129976Z",
     "start_time": "2017-12-20T09:05:33.120363Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T09:06:52.138301Z",
     "start_time": "2017-12-20T09:06:52.114428Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T09:06:54.869883Z",
     "start_time": "2017-12-20T09:06:52.748933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal num_grid_x: 14\n",
      "Optimal num_grid_y: 7\n",
      "Results:\n",
      "SVM:\n",
      "Accuracy: 0.8881118881118881\n",
      "True Positive: 75\n",
      "False Positive: 8\n",
      "True Negative: 52\n",
      "False Negative: 8\n",
      "\n",
      "KNN:\n",
      "Accuracy: 0.7902097902097902\n",
      "True Positive: 61\n",
      "False Positive: 8\n",
      "True Negative: 52\n",
      "False Negative: 22\n",
      "\n",
      "Naive Bayes:\n",
      "Accuracy: 0.6783216783216783\n",
      "True Positive: 41\n",
      "False Positive: 4\n",
      "True Negative: 56\n",
      "False Negative: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MINH.NV193012\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "folder_path = './images/'\n",
    "csv_file_path = 'pollen_data.csv'\n",
    "\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "image_paths = [os.path.join(folder_path, filename) for filename in data['filename']]\n",
    "labels = data['pollen_carrying'].values.astype(int)\n",
    "\n",
    "def load_images():\n",
    "    honeybee_images = []\n",
    "    non_honeybee_images = []\n",
    "\n",
    "    for path, label in zip(image_paths, labels):\n",
    "        img = cv2.imread(path)\n",
    "\n",
    "        # Crop the image to take only the bottom half\n",
    "        height, width, _ = img.shape\n",
    "        img_cropped = img[height // 2:, :]\n",
    "\n",
    "        if label == 1:\n",
    "            honeybee_images.append(img_cropped)\n",
    "        else:\n",
    "            non_honeybee_images.append(img_cropped)\n",
    "\n",
    "    return honeybee_images, non_honeybee_images\n",
    "\n",
    "def resize_images(images, width, height):\n",
    "    resized_images = []\n",
    "    \n",
    "    for img in images:\n",
    "        resized_img = cv2.resize(img, (width, height))\n",
    "        resized_images.append(resized_img)\n",
    "        \n",
    "    return resized_images\n",
    "\n",
    "def extract_color_histogram_local(images, num_grid_x, num_grid_y):\n",
    "    histograms = []\n",
    "    \n",
    "    for img in images:\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Chia hình ảnh thành các ô lưới và tính histogram cho mỗi ô lưới\n",
    "        grid_size_x = hsv.shape[1] // num_grid_x\n",
    "        grid_size_y = hsv.shape[0] // num_grid_y\n",
    "        hist_features = []\n",
    "        \n",
    "        for y in range(num_grid_y):\n",
    "            for x in range(num_grid_x):\n",
    "                grid = hsv[y*grid_size_y:(y+1)*grid_size_y, x*grid_size_x:(x+1)*grid_size_x, :]\n",
    "                hist_h = cv2.calcHist([grid], [0], None, [16], [0, 180])  # Hue histogram\n",
    "                hist_s = cv2.calcHist([grid], [1], None, [8], [0, 256])   # Saturation histogram\n",
    "                hist_v = cv2.calcHist([grid], [2], None, [8], [0, 256])   # Value histogram\n",
    "                \n",
    "                # Chuẩn hóa histogram bằng cách chia cho số lượng pixel trong mỗi ô lưới\n",
    "                hist_h /= grid_size_x * grid_size_y\n",
    "                hist_s /= grid_size_x * grid_size_y\n",
    "                hist_v /= grid_size_x * grid_size_y\n",
    "                \n",
    "                # Ghép các histogram thành một vector đặc trưng\n",
    "                hist_features.extend(hist_h.flatten())\n",
    "                hist_features.extend(hist_s.flatten())\n",
    "                hist_features.extend(hist_v.flatten())\n",
    "        \n",
    "        histograms.append(hist_features)\n",
    "\n",
    "    return histograms\n",
    "\n",
    "def find_optimal_grid_size(images, labels):\n",
    "    best_accuracy = 0\n",
    "    best_num_grid_x = 14\n",
    "    best_num_grid_y = 7\n",
    "\n",
    "#     for num_grid_x in range(10, 15):  \n",
    "#         for num_grid_y in range(5, 8): \n",
    "#             hist_features = extract_color_histogram_local(images, num_grid_x, num_grid_y)\n",
    "\n",
    "#             X_train, X_test, y_train, y_test = train_test_split(hist_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#             # Đào tạo và đánh giá mô hình SVM\n",
    "#             svm_model = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "#             svm_model.fit(X_train, y_train)\n",
    "#             accuracy, _, _, _, _ = evaluate_model(svm_model, X_test, y_test)\n",
    "\n",
    "#             if accuracy > best_accuracy:\n",
    "#                 best_accuracy = accuracy\n",
    "#                 best_num_grid_x = num_grid_x\n",
    "#                 best_num_grid_y = num_grid_y\n",
    "\n",
    "    return best_num_grid_x, best_num_grid_y\n",
    "\n",
    "def prepare_data(honeybee_images, non_honeybee_images):\n",
    "    honeybee_labels = np.ones(len(honeybee_images))\n",
    "    non_honeybee_labels = np.zeros(len(non_honeybee_images))\n",
    "\n",
    "    images = honeybee_images + non_honeybee_images\n",
    "    labels = np.concatenate([honeybee_labels, non_honeybee_labels])\n",
    "\n",
    "    # Resize images\n",
    "    resized_images = resize_images(images, 150, 90)\n",
    "\n",
    "    # Find optimal grid size\n",
    "    num_grid_x, num_grid_y = find_optimal_grid_size(resized_images, labels)\n",
    "    print(f\"Optimal num_grid_x: {num_grid_x}\")\n",
    "    print(f\"Optimal num_grid_y: {num_grid_y}\")\n",
    "\n",
    "    # Extract color histogram local features using the optimal grid size\n",
    "    hist_features = extract_color_histogram_local(resized_images, num_grid_x, num_grid_y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(hist_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_svm(X_train, y_train):\n",
    "    svm = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "    svm.fit(X_train, y_train)\n",
    "    return svm\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    FP = confusion_mat[0, 1]\n",
    "    TP = confusion_mat[1, 1]\n",
    "    FN = confusion_mat[1, 0]\n",
    "    TN = confusion_mat[0, 0]\n",
    "    return accuracy, TP, FP, TN, FN\n",
    "\n",
    "\n",
    "honeybee_images, non_honeybee_images = load_images()\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = prepare_data(honeybee_images, non_honeybee_images)\n",
    "\n",
    "# Train and evaluate SVM\n",
    "svm_model = train_svm(X_train, y_train)\n",
    "svm_accuracy, svm_TP, svm_FP, svm_TN, svm_FN = evaluate_model(svm_model, X_test, y_test)\n",
    "\n",
    "def train_knn(X_train, y_train, n_neighbors=5):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    return knn\n",
    "\n",
    "def train_nb(X_train, y_train):\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    return nb\n",
    "\n",
    "# Train and evaluate KNN\n",
    "knn_model = train_knn(X_train, y_train)\n",
    "knn_accuracy, knn_TP, knn_FP, knn_TN, knn_FN = evaluate_model(knn_model, X_test, y_test)\n",
    "\n",
    "# Train and evaluate NB\n",
    "nb_model = train_nb(X_train, y_train)\n",
    "nb_accuracy, nb_TP, nb_FP, nb_TN, nb_FN = evaluate_model(nb_model, X_test, y_test)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"Results:\")\n",
    "print(\"SVM:\")\n",
    "print(f\"Accuracy: {svm_accuracy}\")\n",
    "print(f\"True Positive: {svm_TP}\")\n",
    "print(f\"False Positive: {svm_FP}\")\n",
    "print(f\"True Negative: {svm_TN}\")\n",
    "print(f\"False Negative: {svm_FN}\")\n",
    "\n",
    "print(\"\\nKNN:\")\n",
    "print(f\"Accuracy: {knn_accuracy}\")\n",
    "print(f\"True Positive: {knn_TP}\")\n",
    "print(f\"False Positive: {knn_FP}\")\n",
    "print(f\"True Negative: {knn_TN}\")\n",
    "print(f\"False Negative: {knn_FN}\")\n",
    "\n",
    "print(\"\\nNaive Bayes:\")\n",
    "print(f\"Accuracy: {nb_accuracy}\")\n",
    "print(f\"True Positive: {nb_TP}\")\n",
    "print(f\"False Positive: {nb_FP}\")\n",
    "print(f\"True Negative: {nb_TN}\")\n",
    "print(f\"False Negative: {nb_FN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T09:06:55.931451Z",
     "start_time": "2017-12-20T09:06:55.916546Z"
    }
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T09:06:56.656917Z",
     "start_time": "2017-12-20T09:06:56.365513Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
